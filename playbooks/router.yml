---
- name: Playbook to set up the BGP routing with a client ec2 in aws
  hosts: localhost
  gather_facts: false
  become: false
  vars_files:
    # Use this to override stuff that won't be committed to git
    - ../overrides.yml

  tasks:
    - name: Get AWS caller identity for Owner tag
      amazon.aws.aws_caller_info:
        profile: "{{ aws_profile }}"
      register: aws_caller_info

    - name: Set AWS ARN User ID
      ansible.builtin.set_fact:
        aws_arn_userid: "{{ aws_caller_info.arn | split('/') | last }}"

    - name: Set AWS ec2 ssh key name
      ansible.builtin.set_fact:
        test_client_ec2_ssh_key_name: "{{ aws_arn_userid }}-ssh-key-rsa"

    - name: Set HUBCONFIG and SPOKECONFIG facts from env variables
      ansible.builtin.set_fact:
        HUBCONFIG: "{{ lookup('env', 'HUBCONFIG') }}"
        SPOKECONFIG: "{{ lookup('env', 'SPOKECONFIG') }}"

    - name: Check for correct HUBCONFIG variable
      ansible.builtin.fail:
        msg: "HUBCONFIG variable needs to be set and pointing to the HUB kubeconfig file"
      when:
        HUBCONFIG is not defined or HUBCONFIG | length == 0

    - name: Check for correct SPOKECONFIG env variable
      ansible.builtin.fail:
        msg: "SPOKECONFIG variable needs to be set and pointing to the REGION kubeconfig file"
      when:
        SPOKECONFIG is not defined or SPOKECONFIG | length == 0

    - name: Show the two cluster kubeconfig paths
      ansible.builtin.debug:
        msg: "HUBCONFIG: {{ HUBCONFIG }} - SPOKECONFIG: {{ SPOKECONFIG }}"

    - name: Check that both clusters are reachable
      ansible.builtin.shell: |
        oc cluster-info
      environment:
        KUBECONFIG: "{{ item }}"
      loop:
        - "{{ HUBCONFIG }}"
        - "{{ SPOKECONFIG }}"

    - name: Get cluster routes and set facts
      ansible.builtin.shell: |
        oc get Ingress.config.openshift.io/cluster -o jsonpath='{.spec.domain}'
      environment:
        KUBECONFIG: "{{ item.config }}"
      register: route_result
      loop:
        - { name: "hub", config: "{{ HUBCONFIG }}" }
        - { name: "spoke", config: "{{ SPOKECONFIG }}" }
    
    - name: Set cluster route info dynamically
      ansible.builtin.set_fact:
        "{{ item.item.name }}_cluster_name": "{{ (item.stdout | split('.'))[1] }}"
        "{{ item.item.name }}_fqdn": "{{ (item.stdout | split('.'))[1:] | join('.') }}"
      loop: "{{ route_result.results }}"        

    - name: Get clusters' aws region
      ansible.builtin.shell: |
        oc get infrastructure cluster -o jsonpath='{.status.platformStatus.aws.region}'
      environment:
        KUBECONFIG: "{{ item.config }}"
      register: aws_region_result
      loop:
        - { name: "hub", config: "{{ HUBCONFIG }}" }
        - { name: "spoke", config: "{{ SPOKECONFIG }}" }

    - name: Set cluster aws region info dynamically
      ansible.builtin.set_fact:
        "{{ item.item.name }}_aws_region": "{{ item.stdout }}"
      loop: "{{ aws_region_result.results }}"        

    - name: We only support clusters in the same region
      ansible.builtin.assert:
        that:
          - hub_aws_region == spoke_aws_region
        fail_msg: "FATAL: we do not support clusters in different regions for now"
      # FIXME: for now we skip this check
      failed_when: false

    - name: Set aws region
      ansible.builtin.set_fact:
        aws_region: "{{ hub_aws_region }}"

    - name: Print AWS info
      ansible.builtin.debug:
        msg: "AWS User: {{ aws_arn_userid }} - AWS Region: {{ aws_region }} - AWS Profile: {{ aws_profile }} - Hub: {{ hub_cluster_name }} - Spoke: {{ spoke_cluster_name }}"

    - name: Get ami image
      ansible.builtin.shell: |
        aws --profile {{ aws_profile }} ec2 describe-images \
        --owners {{ aws_ami_owner }} \
        --filters "Name=name,Values={{ aws_ami_name }}*" "Name=state,Values=available" \
        --region {{ aws_region }} \
        --query 'sort_by(Images, &CreationDate)[-1].ImageId' \
        --output text
      register: test_client_ec2_ami_image_id_raw

    - name: Set ami image fact
      ansible.builtin.set_fact:
        test_client_ec2_ami_image_id: "{{ test_client_ec2_ami_image_id_raw.stdout }}"

    - name: Print ami image use
      ansible.builtin.debug:
        msg: "Using AMI image: {{ test_client_ec2_ami_image_id }}"

    - name: Create key pair to access ec2 with ssh
      amazon.aws.ec2_key:
        profile: "{{ aws_profile }}"
        region: "{{ aws_region }}"
        name: "{{ test_client_ec2_ssh_key_name }}"
        key_material: "{{ ssh_pubkey }}"

    - ansible.builtin.include_tasks: network_task.yml
      loop:
        - { name: "hub", config: "{{ HUBCONFIG }}", cluster_name: "{{ hub_cluster_name }}" }
        - { name: "spoke", config: "{{ SPOKECONFIG }}", cluster_name: "{{ spoke_cluster_name }}" }

    - name: Start an ec2 instance (test-client) 
      amazon.aws.ec2_instance:
        profile: "{{ aws_profile }}"
        region: "{{ aws_region }}"
        name: "test-client-{{ hub_cluster_name }}"
        state: started
        wait: true
        vpc_subnet_id: "{{ hub_public_subnet_id }}"
        instance_type: "{{ test_client_ec2_instance_type }}"
        key_name: "{{ test_client_ec2_ssh_key_name }}"
        security_group: test-client-hub-security-group
        image_id: "{{ test_client_ec2_ami_image_id }}"
        user_data: |
          #cloud-config
          chpasswd:
            expire: false
          password: {{ test_client_ec2_user_password }}
          ssh_pwauth: true
          user: ec2-user
          packages:
          - tmux
          - nc
          - traceroute
          - tcpdump
          - vim
      register: client_instance_info

    - name: Create ENI in spoke's vpc subnet
      amazon.aws.ec2_eni:
        profile: "{{ aws_profile }}"
        subnet_id: "{{ spoke_public_subnet_id }}" # ⬅️ Subnet in VPC B, but same AZ
        security_groups: "test-client-spoke-security-group"
        region: "{{ aws_region }}"
        tags:
          Name: "Spoke-vpc-nic"
      register: eni_info

    - name: Attach the Secondary ENI to the Instance
      amazon.aws.ec2_eni:
        profile: "{{ aws_profile }}"
        eni_id: "{{ eni_info.eni.id }}"
        instance_id: "{{ client_instance_info.instance_ids[0] }}"
        device_index: 1  # ⬅️ Must be 1 or greater for a secondary NIC
        state: attached
        region: "{{ aws_region }}"
